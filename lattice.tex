Gentry's work was a true breakthrough. It not only presented the first, fully homomorphic encryption scheme, but also gave researchers a very powerful tool the \textit{bootstrapping} is. From now on, all we need to construct another FHE scheme, is some suitable (one requirement would be to use a scheme based on ring rather than a group) SHE method, apply appropriate "squashing" to obtain the bootstrapping and we are done. In the following years this is exactly what happened in the academia and the industry.

This section will mostly serve as a survey of the main developments towards more efficient fully homomorphic encryption using lattices and their security based on computational hardness of the underlying problems. We adopt chronological narrative of the sections, starting with the oldest, the GGH algorithm, progressing through works on (ring-)LWE and eventually arriving at the work of Gentry \cite{gentry_phd} on ideal lattices and FHE. For a good survey on the lattice based cryptography, see for example \cite{two_faces}, \cite{book} chapter 6 or \cite{lattice-survey}.

\krzys{Optional: Add results about hardness to make the section more concrete on how cryptography research really looks like}
\subsection{The GGH public key cryptosystem}
We will start this section with a somewhat simpler cryptosystem that was developed by Goldreich, Goldwasser and Halevi and presented in 1997 \cite{ggh} called, the GGH cryptosystem. This scheme, rather than using ideal lattices (i.e. lattices that are also ideals in the ring of integers), relies on general properties of lattices. Namely, the hardness of the SVP and CVP (see section \ref{hardness}).

\subsubsection*{Idea behind the scheme}
The basic GGH cryptosystem, as mentioned before, is based on the problem of finding the closest vector in the lattice $\mathcal{L}$ to a given point in the ambient space $\R^n$. We are given two bases, call them $\Bg$ and $\Bb$. The $\Bb$ will be our public key and $\Bg$ the secret key. The $\Bb$ consists of long and highly non-orthogonal vectors, as opposed to $\Bg$. Our secret message $\bm{m}$ is represented as a binary vector which we will use to form a linear combination $\bm{s} = \sum m_i \bm{v}_i^{bad} \in \mathcal{L}$ of the vectors in $\Bb$. We now add some small and random\footnote{some small note about the "randomness" of this e} error $\bm{e} \in \R^n$ to obtain the ciphertext $\bm{c} = \bm{s} + \bm{e} = \sum m_i \bm{v}_i^{bad} + \bm{e} \in \R^n$ - some point that is not in the lattice, but rather, very close to a point in it.\\
To decrypt, we can use our good basis $\Bg$ to represent $\bm{c}$ and, for example Babai's algorithm\footnote{Simply stated, if the vectors of the basis are sufficiently orthogonal to one another, then this algorithm solves CVP. However, if the Hadamard ratio is too small, the algorithm fails to find the closest vector \cite{book}.} to find $\bm{v}$ and represent it in terms of the basis $\Bg$ to recover $\bm{m}$. On the other hand, any eavesdropping adversary that is trying to learn our secret, is left with some bad basis that will be of no help in solving the CVP.

\subsubsection*{GGH construction - concretely}
\noindent\fbox{%
    \parbox{\textwidth}{%
$\alg{KeyGen}$:
\begin{itemize}
    \item Pick a basis $(\bm{v}_1, \bm{v}_2, \dots, \bm{v}_n) \subset \Z^n$ such that they are reasonably orthogonal to one another - i.e. with small Hadamard ratio. We will associatie the vectors $\bm{v}_1, \bm{v}_2, \dots, \bm{v}_n$ as the $n$-by-$n$ matrix $\bm{V}$ and let $\mathcal{L}$ be the lattice generated by these vectors. This is our good basis $\Bg$ - the \textbf{private key}.
    \item Pick an $n$-by-$n$ matrix $\bm{U}$ with integer coefficients and determinant $\pm 1$ and compute $\bm{W} = \bm{UV}$. The column vectors $\bm{w}_1, \bm{w}_2, \dots, \bm{w}_n$ of $\bm{W}$ are the bad basis $\Bb$ of $\mathcal{L}$ - the \textbf{public key}\footnote{As an alternative, in \cite{hnf}, Micciancio suggested to use the Hermite Normal Form (HNF) of $\Bg$ which essentially provides the worst possible lattice choice from both cryptoanalitical and efficiency point of view.}.
\end{itemize}
$\alg{Encrypt}$:
$\alg{Decrypt}$:
}} \\

The greatest drawback of GGH is that there were no proofs of security presented along the algorithm, only heuristic assumptions. This motivated researchers to look for possible exploits beased on the choice of parameters. Indeed, this scheme turned out to be insecure for most practical choices of the security parameter only 2 years later, in \cite{break1} and broken completely in \cite{break2}. Nonetheless, the ideas presented there have served as a basis for many schemes that are proven to be secure, like for example LWE, and has led to a plethora of applications.
\subsection{Learning With Errors}
Let us now begin with what went wrong in GGH. Namely, first prove the hardness of a problem, then use it to construct a secure and efficient cryptosystem. In this section we introduce \textit{Learning With Errors} (LWE) problem and the cryptosystem introduced by Oded Regev in \cite{regev} (he won the 2018 GÃ¶del Prize for this work). This very important work in the field of lattice based cryptography is, up to the date \krzys{im not sure if this statement is true, i need to look more into it}, one of the most efficient schemes with an actual proof of security.

\iffalse
\subsubsection*{Lattices - Part II}

\begin{definition}[Dual]
    For a lattice $\mathcal{L} \subset \R^n$ its $\Z$\textit{-dual} is
    $$ \mathcal{L}^{\vee} = \{ y \in \R^n : y \cdot \mathcal{L} \subset \Z \}.$$
    Here, the $\cdot$ means the usual dot product.
\end{definition}

We simply require that the elements of the dual are precisely those vectors that yield an integer when "multiplied" with an element of our lattice. Note that this is different from our standard definition of a dual. Namely, it is not the orthogonal compliment of our starting space, i.e. not all of the elements of the dual have 0 dot product against the vectors of the lattice.

\begin{example}
    Take $\mathcal{L}= \Z 
        \big(\begin{smallmatrix} 1\\2 \end{smallmatrix}\big) + 
        \Z \big(\begin{smallmatrix} 0\\ 1 \end{smallmatrix}\big)$
        To calculate the dual of $\mathcal{L}$ we need our $y = \big(\begin{smallmatrix}
          a\\b\end{smallmatrix}\big)$ elements to satisfy $a \in \Z$ and $2a + b \in \Z$ which is equivalent to asking $a \in (1/2)\Z$ and so $\mathcal{L}^{\vee} = \big(\begin{smallmatrix}
          1/2\\0
        \end{smallmatrix}\big)\Z + \big(\begin{smallmatrix}
          0\\1
        \end{smallmatrix}\big) \Z$
\end{example}

Note that $\mathcal{L}^{\vee}$ is itself a lattice of the same dimension.
\fi

\subsubsection*{LWE problem}
There are multiple equivalent definitions of this problem. We adopt the notation and approach introduced in the original paper \cite{regev} by Regev. \\
The problem is parametrized by positive integers $n$, $m$ and prime $q$, as well as an error distibution $\chi$ over $\Z_q$. It is now defined as follows. We are given $m$ equations of the form $(\bm{a}_i, b_i = \langle \bm{a}_i, \bm{s} \rangle + e_i)$ and are asked to find the vector $\bm{s} \in \Z_q^n$. Here, $\bm{a}_i$ are chosen uniformly and independently from $\Z_q^n$, $b_i \in \Z_q$ and $\langle \cdot, \cdot \rangle$ denotes the usual dot product. The errors $e_i$ are obtained by sampling independently from the probability distribution $\chi : \Z_q \rightarrow \R_{+}$ on $\Z_q$. To now denote the problem of recovering $\bm{s}$ from such equations, by $\text{LWE}_{q, \chi}$ (learning with error)\footnote{It is worth noting that LWE is a generalization of 'learning parity with noise' in which case $q=2$ and the distribution $\chi$ is just a Bernoulli distribution over $\{0,1\}$ with some parameter $\epsilon > 0$.}. \\
The central part of \cite{regev} revolves around proving conjured hardness of LWE. Specifically, that for appropriately chosen $q$ and $\chi$, a \textit{quantum} reduction algorithm exists that approximates worst-case lattice problems. A still open problem is to find a \textit{classical} reduction algorithm that proves the hardness. The result is loosely stated as follows.

\begin{theorem}[Theorem 1.1 in \cite{regev}]
    Let $n$, $q$ be integers and $\alpha \in (0, 1)$ be such that $\alpha q > 2 \sqrt{n}$. If there exists an efficient algorithm that solves $\text{LWE}_{q, \bar{\Psi}_{\alpha}}$, then there exists an efficient quantum algorithm that approximates the decision version of the shortest vector problem (\prob{GapSVP}) and the shortest independent vectors problem (\prob{SIVP}) to within $\tilde{O}(n/\alpha)$ in the worst case.	
\end{theorem}

Unwrapping this statement yields the following. As said before we need an appropriate choice of paramenters to obtain our results and $\alpha$ is one of those. It specifies the shape of the $\bar{\Psi}_{\alpha}$ distribution. This one is almost identical to the discrete Gaussian distribution over $\Z_q$ that is centered around 0 with standard deviation $\alpha q$\footnote{Originally, Regev considered the continuous Gaussian and rounded the result to the nearest integer. This does not exactly yield the discrete distribution but thanks to \cite{discr} we know how the problem can be fixed - \cite{lattice-survey}.}. The theorem can be rephrased as follows. Imagine that we have an efficient algorithm that solves the $\text{LWE}_{q, \bar{\Psi}_{\alpha}}$. Then, there exists a quantum solution to worst-case lattice problems, namely \prob{GapSVP} and \prob{SIVP}.
\subsubsection*{LWE cryptosystem}
$\alg{KeyGen:}$
\begin{itemize}
    \item
\end{itemize}

\subsubsection*{Ring-LWE}
\cite{ring-lwe} 
Toward basing fully homomorphic encryption on worst-case hardness

\subsection{Fully Homomorphic Encryption Using Ideal Lattices}
explain here how we can construct a really nice homomorphic encryption scheme using ideal lattices \cite{gentry}. present the 
\subsection{On Ideal Lattices and Learning With Errors Over Rings}
this is somewhat too difficult for me i think so ill just present main findings without proofs and details \cite{regev}, \\
First explain what lattices are. \\
How do lattices relate to LWE? The secret key is associated with a random vector. \\
then show how ring-lwe satisfies both of our requirements \cite{ring-lwe}, namely, the believed hardness for quantum computers (SVP or approximate SVP) and FHE. Show also the problem with ring-LWE because the lattices that are used there are ideal lattices which obviously possess more structure than "normal" lattices.
