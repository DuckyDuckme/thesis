\subsection{Notation}
Most of the notation is ``standard'' in the field of number theory and cryptography. Nonetheless, to avoid any misunderstandings and simplify some statements, we will present the notation used throughout the text. Anything that is not mentioned here shall be defined ``on the go'' with definitions and such. \\

\noindent Any scalars $a, t, \beta, \dots$ are represented by non-bold, latin or greek letters.\\
Bold symbols $\bm{v}, \bm{x}, \bm{s}, \dots$ will denote vectors. \\
$\alg{Algorithms}$ will be represented by $\alg{textsf font}$ names such as $\alg{Encrypt}$ or $\alg{Evaluate}$.\\
Traditionally, the symbols $\Z, \Q, \R, \C$ shall represent the sets of integers, rational, real and complex numbers, respectivelly.\\
Additionally, for any real $m \geq 0$, $\flo{m}$ shall denote greatest integer not exceeding $m$, $\round{m} = \flo{m + \frac{1}{2}}$ and $[m]$ is the set $\{1, 2, \dots, \flo{m}\}$.\\
%When the situation demands us to make use of many variables and/or indicies, we will be using Eisenstein notation which is defined as \krzys{fill that in}

\subsection{Lattices}
\subsubsection*{Basic definitions}
We define a \textit{lattice} as a discrete additive subgroup of $\R^n$. Once we fix a basis $\B = (\bm{b}_1, \dots ,\bm{b}_n) \in \R^n$ we can then describe the lattice as
\[ \Lambda = \mathcal{L}(\bm{B}) = \Bigl\{ \sum_i z_i \bm{b}_i : z_i \in \Z \Bigl\}.\]
In other words, $\Lambda$ is the $\Z$-span of the specific basis $\B$.

There are many bases for a lattice (actually, for $n \geq 2$, there are infinitely many as can be proven using a diagonalization argument), some ``better'' than others. This will be the foundation for some of the cryptosystems later like the GGH.

\begin{example}
    The simplest example of a lattice is the $\Z^n$ itself. Taking the standard basis $\B_1 = (\bm{e}_1, \dots, \bm{e}_n)$ we obtain
	\[ \mathcal{L}(\bm{B}_1) = \Bigl\{ \sum_i z_i \bm{e}_i : z_i \in \Z \Bigl\} = \Z^n. \]
\end{example}
More generally, $\Lambda$ is a lattice of rank $m$ in $\R^n$ if it is a rank $m$ free abelian group. Recall that we call a group \textit{free abelian group} of rank $m$ if it can be written as $\Lambda = \Z\beta_1 \oplus \cdots \oplus\Z\beta_m$ with $\beta_1, \dots, \beta_m$ linearly independent over $\R$ where $\oplus$ represents the direct sum. In this paper we will only consider lattices of full rank $n$. 

\begin{remark}
    We can also view the vectors $\bm{b}_i$ as the columns of the matrix $\B \in \R^n \cross \R^n$ in which case, our definition becomes:
    $$\Lambda = \mathcal{L}(B) = \{\bm{Bz} :  \bm{z} \in \Z^n \}.$$
\end{remark}

Reciprocally, any matrix $\bm{B} \in GL_n(\R)$ spans a lattice: the set of all integer linear combinations of its rows.

\begin{example}
\begin{enumerate}
    \item $\mathcal{L} = \begin{pmatrix}
        1 & 0\\
        0 & 1
	\end{pmatrix}$ in which case $\bm{b}_1 = \big(\begin{smallmatrix}
          1\\
          0
	\end{smallmatrix}\big)$ and $\bm{b}_2 = \big(\begin{smallmatrix}
          0\\
          1
        \end{smallmatrix}\big)$
    \item $\mathcal{L} = \{(z_1,z_2) : z_1 + z_2 \text{ is even}\}$
    \item $\mathcal{L} = \begin{pmatrix}
        1/3 & \pi\\
        0 & 21/7
        \end{pmatrix}$
\end{enumerate}
\end{example}

As noted before, the basis of a lattice is not unique. There is one that is particularly interesting to us, namely, the \textit{Hermite Normal Form} (HNF). A basis $\B$ is in HNF if it is upper triangular (or lower triangular - does not matter as long as one is consistent), all elements on the diagonal are strictly positive and any other element $\bm{b}_{i,j}$ satisfies $0 \leq \bm{b}_{i,j} < \bm{b}_{i,i}$.

\subsubsection*{Fundamental Domain}
\begin{definition}[Fundamental Domain] \label{fundamental}
    Let $\mathcal{L}$ be a lattice of dimension $n$ and let $(\bm{b}_1, \dots, \bm{b}_n)$ be a basis for $\mathcal{L}$. The \textit{fundamental domain} (or \textit{fundamental parallelepiped}) for $\mathcal{L}$ corresponding to this basis is the set
    $$ \mathcal{F}(\bm{b}_1, \dots, \bm{b}_n) = \{t_1\bm{b}_1 + \cdots + t_n\bm{b}_n : 0 \leq t_i < 1 \}.$$
\end{definition}

We define the \textit{volume} of $\mathcal{F}(\bm{B})$ as the volume of the corresponding parallelepiped in $\R^n$. The \textit{volume} -- closely connected to the determinant -- plays a very important role in our study which will become evident in later chapters. One of the advantages, of defining the fundamental domain, is that we can formalize the notion of area (or the determinant) of any given lattice. Recall that a lattice is just a countable collection of points and therefore has no volume by itself. This, however, is resolved by introducing the following.

\begin{definition}
    Let $\mathcal{L}$ be a lattice of dimension $n$ and let $\mathcal{F}(\bm{B})$ be a fundamental domain for $\mathcal{L}$ over some basis $\bm{B}$. We define the \textit{determinant} of that lattice as
	\[ \det (\mathcal{L}) = \VF{\bm{B}} = |\det (\bm{B}) | \]
\end{definition}

The next two propositions are arguably the two most fundamental resuls for lattice based cryptography. The first one, states that the $\det (\mathcal{L})$ does not depend on the choice of the basis for that lattice. The second, that our whole ambient space $\R^n$ can be described using only vectors from the lattice and the fundamental domain. We will only give an outline of the proofs for the sake of keeping this section compact. Full proofs, however, can be found in \cite{book}, chapter 6.4.

\begin{lemma}
    The $\det (\mathcal{L})$ of an $n$-dimensional lattice is invariant under the choice of the basis.
\end{lemma}

\begin{proof}[Outline of the proof]
    Let $\bm{B}_1, \bm{B}_2$ be two bases for a lattice $\mathcal{L}$. The crucial part of the proof is to note that any two bases are related by some unimodular matrix $U$ (i.e. a matrix with the determinant of $\pm 1$) s.t. $\bm{B}_1 = U \bm{B}_2$. Then it easily follows that 
	\[| \det (\bm{B}_1) | = \det (\mathcal{L}) = | \det (U \cdot \bm{B}_2) | = | \det(U) | \cdot | \det(\bm{B}_2) | = | \det(\bm{B}_2)| \]
\end{proof}

From now on we will write $\mathcal{F}$ to denote the fundamental domain of the lattice without specifying the basis.

\begin{proposition}
    Let $\mathcal{L} \subset \R^n$ be a lattice of dimension $n$ and let $\mathcal{F}$ be a fundamental domain for $\mathcal{L}$. Then every vector $\bm{v} \in \R^n$ can be written in the form 
    $$\bm{v} = \bm{f} + \bm{t}$$
    for $\bm{f} \in \mathcal{F}$ and $\bm{t} \in \mathcal{L}$ both unique and associated to the original $\bm{v}$.
\end{proposition}

Equivalently, the space $\R^n$ is spanned exactly (without overlap) by shifting the fundamental domain by the vectors from our lattice.
$$ \R^n = \bigcup_{\bm{t} \in \mathcal{L}} \{\bm{f} : \bm{f} \in \mathcal{F} \}$$

\begin{remark}
    Sometimes the \textit{fundamental domain} is refered to as a parallelepiped or parallelotope and denoted by caligraphic $\mathcal{P}$. If we take a matrix $\bm{B}$ to represent our lattice $\mathcal{L}$, then $\mathcal{P}_{1/2}(\bm{B}) = \{\bm{x}\bm{B}, \bm{x} \in [-1/2, 1/2]^n \}$ can also represent the (shifted by a half) fundamental domain of $\mathcal{L}$ (like for example in \cite{gentry}).
\end{remark}
\iffalse
We will now present two results that give us an upper bound on the length of the shortest vector in a lattice. This will later on be useful to determine the security and/or correctness of our schemes. These theorems are due to Hermite (1822 - 1901) and Minkowski (1864 - 1909).

\begin{theorem}[Hermite's Theorem]
    Every lattice $\mathcal{L}$ of dimension $n$ contains a nonzero vector $v \in \mathcal{L}$ satisfying
    $$ \norm{v} \leq \sqrt{n} \det(\mathcal{L})^{\frac{1}{n}}.$$
\end{theorem}
\krzys{add minkowski's theorem}\\
\fi
We can also need some notion of the shortest possible vector of a lattice. These will be very useful in the study of the hardness of a given problem.
\begin{definition}
	For a $n$-dimensional lattice $\Ll$, we denote its shortest nonzero vector (also called the \textit{minimum distance}) by $\lambda_1(\Ll)$. Formally
	\[ \lambda_1(\Ll) := \min_{0 \neq \bm{v} \in \Ll} ||\bm{v}|| \]
	More generally, for $1 \leq i \leq n$, the $i$th sucessive minimum of $\Ll$ is
	\[\lambda_i(\Ll) := \inf \{r : \Ll \text{ has $i$ linearly independent vectors of length at most } r \}. \]
\end{definition}
For example, in order to be able to go ``away'' from the lattice $\Ll$ ``out'' into the ambient space $\R^n$ and still be able to return to the original vector, we need to make sure the distance $d$ we travel is at most $\lambda_1(\Ll)/2$. This is for example a requirement in the \prob{BDD} problem where the decoding is \textit{promised}. For the exact definition see Section \ref{hardness}.

Aditionally, most of the problems used in this paper are the \textit{approximate} versions to some varying constant usually called $\gamma$. As we will see later, $\gamma$ very often depends on $\lambda_1(\Ll)$ which roughly measures how ``strict'' or ``precise'' we can make our problem. This will be made explicing in the Section \ref{hardness} on the hardness and complexity theory.

\paragraph{Dual}
\begin{definition}[Dual]
    For a lattice $\Ll \subset \R^n$ its $\Z$\textit{-dual} is
    \[ \Lld = \{ y \in \R^n : \langle y,\Ll \rangle \subseteq \Z \}.\]
\end{definition}

We simply require that the elements of the dual to be precisely those vectors, that yield an integer when ``multiplied'' with an element of our lattice. Note that this is different from our standard definition of a dual. Namely, it is not the orthogonal compliment of our starting space, i.e. not all of the elements of the dual have 0 dot product against the vectors of the lattice.

\begin{example}\label{ld-ex}
    Take $\mathcal{L}= \Z 
        \big(\begin{smallmatrix} 1\\2 \end{smallmatrix}\big) + 
        \Z \big(\begin{smallmatrix} 0\\ 1 \end{smallmatrix}\big)$.
        To calculate the dual of $\mathcal{L}$ we need our $y = \big(\begin{smallmatrix}
          a\\b\end{smallmatrix}\big)$ elements to satisfy $a +2b \in \Z$ and $b \in \Z$ which is equivalent to asking $a \in (1/2)\Z$ and so $\mathcal{L}^{\vee} = \big(\begin{smallmatrix}
          1/2\\0
        \end{smallmatrix}\big)\Z + \big(\begin{smallmatrix}
          0\\1
        \end{smallmatrix}\big) \Z$
        See Figure \ref{lattices} where the red vectors represent the basis.
\end{example}

Note that $\mathcal{L}^{\vee}$ is itself a lattice of the same dimension. One can imagine the dual as the original lattice ``flipped'' in the sence that the shortes element becomes the longest and vice versa.
\begin{figure}[ht]
    \caption{Lattice $\Ll$ from example \ref{ld-ex} and its dual.}
        \label{lattices}
        \centering
        \begin{subfigure}{.5\textwidth} 
                \centering
                \includegraphics[scale=0.5]{lattice.png}
                \caption{$\Ll$}
        \end{subfigure}%
        \begin{subfigure}{.5\textwidth}
                \centering
                \includegraphics[scale=0.5]{lattice-d.png}
                \caption{$\Lld$}
        \end{subfigure}
\end{figure}

\input{ant}

\subsection{Complexity Theory and Hard Problems} \label{hardness}
When talking about cryptography, we cannot avoid talking about algorithms since an encryption scheme is simply a instruction on how to encode sensitive data. We will thus require some terminology from computational complexity theory -- a field on the overlap of computer science and mathematics. The problems the field is concerned are those of the time and space required for solving computational problems. Most of the time, the goal of the study is to prove the lower bound on the resources required to solve a problem using the best know algorithm. For example, how long does it take to find a factorization of a large composite number. The goal of this section is to give an overview of few parts of the field that we will be using throughout the paper. 

\subsubsection*{Complexity theory}
We begin with necessary terminology. Throughout this section, $n$ shall denote the ``size'' of the input to the algorithm. Here the word size could mean many things like for example the bit-length of a number or its value in the base 10 representation.

In order to represent the time or space required to solve the problem, most of the time we will use the ``big-O'' notation. For any function $f$ and $g$ of some variable $x$, we say that $f(x) \in O(g(x))$ if there exists some constant $M > 0$ and $x_0$ such that $f(x) \leq Mg(x)$ for all $x \geq x_0$. Roughly speaking, the function $g$ will eventually ``grows faster'' than $f$.

\pinar{will wait}
mention "efficient", "negligible", "hard" and define reductions. show some problems like svp, cvp, bdd
In this section we will briefly introduce what it means for a problem to be considered \textit{hard} and provide couple of examples
We define a \prob{negligible} amount in $n$ as an amount that is asymptotically smaller than $n^{-c}$ for any constant $c > 0$. More precisely, 
\begin{definition}\label{negl}
    $f (n)$ is a \prob{negligible} function in $n$ if $\lim_{n \to \infty}n^{-c} f (n) = 0$ for any $c > 0$.
\end{definition}
The best know examples
\prob{FACTORIZE}
\subsubsection{Hard problems}
\begin{definition}[FACTORIZE]
\end{definition}
\begin{definition}[SVP]
\end{definition}
\subsubsection*{Basic cryptographic concepts}
One-way function\\
semantic security

